{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2466/2466 [00:01<00:00, 1844.84it/s]\n"
     ]
    }
   ],
   "source": [
    "### Load and preprocess the dataset\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tqdm import tqdm \n",
    "\n",
    "image_height = 22\n",
    "image_width = 54\n",
    "batch_size = 32\n",
    "\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "image_folder = \"./images_w_labels\"\n",
    "for filename in tqdm(os.listdir(image_folder)):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = load_img(os.path.join(image_folder, filename), target_size=(image_height, image_width))\n",
    "        img_array = img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "\n",
    "        # Extract the labels from the file name\n",
    "        label = filename.split(\".\")[0]  # Remove the file extension\n",
    "        labels.append([int(digit) for digit in label])\n",
    "\n",
    "image_data = tf.convert_to_tensor(image_data)\n",
    "labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_data, labels))\n",
    "dataset = dataset.shuffle(len(image_data))\n",
    "dataset = dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split ratios\n",
    "train_ratio = 0.7  # 70% of data for training\n",
    "val_ratio = 0.15  # 15% of data for validation\n",
    "test_ratio = 0.15  # 15% of data for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "test_size = int(test_ratio * len(dataset))\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size).take(val_size)\n",
    "test_dataset = dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 22, 54, 3) (32, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:\n",
    "    print(i[0].shape, i[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 566196.3125 - accuracy: 0.3003 - val_loss: 1860945.5000 - val_accuracy: 0.2756\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 5365002.0000 - accuracy: 0.2865 - val_loss: 10786529.0000 - val_accuracy: 0.2585\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 18176414.0000 - accuracy: 0.2697 - val_loss: 27491934.0000 - val_accuracy: 0.2898\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 39586540.0000 - accuracy: 0.2940 - val_loss: 49026176.0000 - val_accuracy: 0.3011\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 66583988.0000 - accuracy: 0.2789 - val_loss: 91884952.0000 - val_accuracy: 0.3125\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 105073928.0000 - accuracy: 0.2784 - val_loss: 118630760.0000 - val_accuracy: 0.2472\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 139562304.0000 - accuracy: 0.2841 - val_loss: 151111536.0000 - val_accuracy: 0.2869\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 174895072.0000 - accuracy: 0.2865 - val_loss: 202685968.0000 - val_accuracy: 0.3125\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 212726400.0000 - accuracy: 0.2807 - val_loss: 251886096.0000 - val_accuracy: 0.2727\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 284119744.0000 - accuracy: 0.2749 - val_loss: 303998080.0000 - val_accuracy: 0.2699\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "model = tf.keras.Sequential([\n",
    "\tDefaultConv2D(filters=64, kernel_size=7, input_shape=(22, 54, 3)),\n",
    "\tMaxPool2D(),\n",
    "\tDefaultConv2D(filters=128),\n",
    "\tDefaultConv2D(filters=128),\n",
    "\tMaxPool2D(),\n",
    "\tDefaultConv2D(filters=256),\n",
    "\tDefaultConv2D(filters=256),\n",
    "\tMaxPool2D(),\n",
    "\tFlatten(),\n",
    "\tDense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "\tDropout(0.5),\n",
    "\tDense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "\tDropout(0.5),\n",
    "\tDense(units=4, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# # Model Architecture\n",
    "# model = tf.keras.Sequential([\n",
    "#     layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(22, 54, 3)),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(4, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Evaluation\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Prediction\n",
    "predictions = model.predict(new_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
